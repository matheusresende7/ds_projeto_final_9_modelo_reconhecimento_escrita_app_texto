{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 07. Model CNN - Keras Tuner"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Importando as bibliotecas"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys\n",
    "import os\n",
    "from pathlib import Path\n",
    "sys.path.append('..')\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import tensorflow as tf\n",
    "from tensorflow import keras\n",
    "import keras_tuner as kt"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Configurando para serem exibidas apenas mensagens de erro no Tensor Flow"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "os.environ['TF_CPP_MIN_LOG_LEVEL'] = '2' # Configurando para serem exibidas apenas mensagens de erro no Tensor Flow"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Lendo o dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = keras.datasets.mnist # Armazenando o dataset em uma variável"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "(x_train, y_train), (x_test, y_test) = df.load_data() # Armazenando os dados do df já divididos em X e Y de treino e teste"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Definindo a função Tuner a partir de um pipeline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "def model_builder(hp): # Criando a função que cria o modelo usando o keras tuner\n",
    "\n",
    "    # Etapa inicial\n",
    "    model = keras.models.Sequential() # Instanciando o modelo\n",
    "\n",
    "    # Etapas de pré processamento\n",
    "    model.add(keras.layers.InputLayer(input_shape=(28, 28, 1))) # Passando o shape dos dados para o modelo\n",
    "    model.add(keras.layers.Rescaling(scale=1./255)) # Fazendo o rescaling dos dados entre 0 e 255 para 0 e 1\n",
    "\n",
    "    # Etapas de data augmentation\n",
    "    model.add(keras.layers.RandomRotation(0.1)) # Aplicando o Data Augmentation para aumento dos dados, nesse caso rotação da imagem\n",
    "    model.add(keras.layers.RandomTranslation(height_factor=0.1, width_factor=0.1)) # Aplicando o Data Augmentation para aumento dos dados, nesse caso translação da imagem\n",
    "    model.add(keras.layers.RandomZoom(0.1)) # Aplicando o Data Augmentation para aumento dos dados, nesse caso zoom na imagem\n",
    "\n",
    "    # Etapas de CNN\n",
    "    model.add(keras.layers.Conv2D(\n",
    "        hp.Int('conv_1_filters', min_value=16, max_value=64, step=2, sampling='log'), # Ajustando hiperparâmetros com o keras tuner\n",
    "        (3, 3), \n",
    "        activation='relu')) # Adicionando uma camada convolucional\n",
    "    model.add(keras.layers.MaxPooling2D()) # Adicionando o Max Pooling visando desconsiderar o fundo da imagem\n",
    "    model.add(keras.layers.Dropout(0.2)) # Desligando alguns neurônios aleatóriamente para tentar reduzir o overfitting\n",
    "    model.add(keras.layers.Conv2D(\n",
    "        hp.Int('conv_2_filters', min_value=32, max_value=128, step=2, sampling='log'), # Ajustando hiperparâmetros com o keras tuner\n",
    "        (3, 3), \n",
    "        activation='relu')) # Adicionando uma camada convolucional\n",
    "    model.add(keras.layers.MaxPooling2D()) # Adicionando o Max Pooling visando desconsiderar o fundo da imagem\n",
    "    model.add(keras.layers.Dropout(0.2)) # Desligando alguns neurônios aleatóriamente para tentar reduzir o overfitting\n",
    "\n",
    "    # Etapas de camadas ocultas\n",
    "    model.add(keras.layers.Flatten()) # Realizando a redução de dimensionalidade/achatamento\n",
    "    model.add(keras.layers.Dense(10, activation='softmax')) # Passando a camada de sáida (10 = valores de resultados possíveis (0 a 9))\n",
    "\n",
    "    # Etapas de compilação\n",
    "    optimizer = keras.optimizers.Adam(learning_rate=hp.Choice('learning_rate', values=[1E-2, 1E-3, 1E-4])) # Definindo o otimizador\n",
    "    loss = keras.losses.SparseCategoricalCrossentropy() # Definindo a função de busca\n",
    "    metric = keras.metrics.SparseCategoricalAccuracy() # Definindo a métrica a ser considerada durante o treinamento\n",
    "    model.compile(optimizer=optimizer, loss=loss, metrics=[metric]) # Compilando o modelo\n",
    "\n",
    "    return model # Retornando o modelo"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "ename": "FailedPreconditionError",
     "evalue": "tuner_history is not a directory",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mFailedPreconditionError\u001b[0m                   Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[7], line 1\u001b[0m\n\u001b[1;32m----> 1\u001b[0m tuner \u001b[38;5;241m=\u001b[39m \u001b[43mkt\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mHyperband\u001b[49m\u001b[43m(\u001b[49m\n\u001b[0;32m      2\u001b[0m \u001b[43m    \u001b[49m\u001b[43mmodel_builder\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;66;43;03m# Passando a função definida anteriormente com os detalhes da otimização de hiperparâmetros\u001b[39;49;00m\n\u001b[0;32m      3\u001b[0m \u001b[43m    \u001b[49m\u001b[43mobjective\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43m \u001b[49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43mval_loss\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;66;43;03m# Definindo o objetivo da otimização de hiperparâmetros\u001b[39;49;00m\n\u001b[0;32m      4\u001b[0m \u001b[43m    \u001b[49m\u001b[43mmax_epochs\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43m \u001b[49m\u001b[38;5;241;43m10\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;66;43;03m# Definindo o número máximo de epochs, ou seja, quantas vezes o modelo passará por todo o conjunto de treino durante o ajuste\u001b[39;49;00m\n\u001b[0;32m      5\u001b[0m \u001b[43m    \u001b[49m\u001b[43mfactor\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43m \u001b[49m\u001b[38;5;241;43m3\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;66;43;03m# Fator de redução no número de epochs\u001b[39;49;00m\n\u001b[0;32m      6\u001b[0m \u001b[43m    \u001b[49m\u001b[43mdirectory\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43m \u001b[49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43mtuner_history\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;66;43;03m# Criando uma pasta para armazenar os resultados do treinamento, que podem ser reaproveitados posteriormente\u001b[39;49;00m\n\u001b[0;32m      7\u001b[0m \u001b[43m    \u001b[49m\u001b[43mproject_name\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43m \u001b[49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43mmnist_projec\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m \u001b[49m\u001b[38;5;66;43;03m# Definindo o nome do projeto e da pasta que vai armazenar os resultados do treinamento\u001b[39;49;00m\n\u001b[0;32m      8\u001b[0m \u001b[43m)\u001b[49m \u001b[38;5;66;03m# Criando uma variável para armazenar as informações da otimização de hiperparâmetros\u001b[39;00m\n",
      "File \u001b[1;32mc:\\Users\\mathe\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\keras_tuner\\src\\tuners\\hyperband.py:420\u001b[0m, in \u001b[0;36mHyperband.__init__\u001b[1;34m(self, hypermodel, objective, max_epochs, factor, hyperband_iterations, seed, hyperparameters, tune_new_entries, allow_new_entries, max_retries_per_trial, max_consecutive_failed_trials, **kwargs)\u001b[0m\n\u001b[0;32m    393\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21m__init__\u001b[39m(\n\u001b[0;32m    394\u001b[0m     \u001b[38;5;28mself\u001b[39m,\n\u001b[0;32m    395\u001b[0m     hypermodel\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mNone\u001b[39;00m,\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m    406\u001b[0m     \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs,\n\u001b[0;32m    407\u001b[0m ):\n\u001b[0;32m    408\u001b[0m     oracle \u001b[38;5;241m=\u001b[39m HyperbandOracle(\n\u001b[0;32m    409\u001b[0m         objective,\n\u001b[0;32m    410\u001b[0m         max_epochs\u001b[38;5;241m=\u001b[39mmax_epochs,\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m    418\u001b[0m         max_consecutive_failed_trials\u001b[38;5;241m=\u001b[39mmax_consecutive_failed_trials,\n\u001b[0;32m    419\u001b[0m     )\n\u001b[1;32m--> 420\u001b[0m     \u001b[38;5;28;43msuper\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[38;5;21;43m__init__\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43moracle\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43moracle\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mhypermodel\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mhypermodel\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[1;32mc:\\Users\\mathe\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\keras_tuner\\src\\engine\\tuner.py:122\u001b[0m, in \u001b[0;36mTuner.__init__\u001b[1;34m(self, oracle, hypermodel, max_model_size, optimizer, loss, metrics, distribution_strategy, directory, project_name, logger, tuner_id, overwrite, executions_per_trial, **kwargs)\u001b[0m\n\u001b[0;32m    114\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m hypermodel \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m \u001b[38;5;129;01mand\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m\u001b[38;5;18m__class__\u001b[39m\u001b[38;5;241m.\u001b[39mrun_trial \u001b[38;5;129;01mis\u001b[39;00m Tuner\u001b[38;5;241m.\u001b[39mrun_trial:\n\u001b[0;32m    115\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m(\n\u001b[0;32m    116\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mReceived `hypermodel=None`. We only allow not specifying \u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m    117\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m`hypermodel` if the user defines the search space in \u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m    118\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m`Tuner.run_trial()` by subclassing a `Tuner` class without \u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m    119\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124musing a `HyperModel` instance.\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m    120\u001b[0m     )\n\u001b[1;32m--> 122\u001b[0m \u001b[38;5;28;43msuper\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[38;5;21;43m__init__\u001b[39;49m\u001b[43m(\u001b[49m\n\u001b[0;32m    123\u001b[0m \u001b[43m    \u001b[49m\u001b[43moracle\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43moracle\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    124\u001b[0m \u001b[43m    \u001b[49m\u001b[43mhypermodel\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mhypermodel\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    125\u001b[0m \u001b[43m    \u001b[49m\u001b[43mdirectory\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mdirectory\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    126\u001b[0m \u001b[43m    \u001b[49m\u001b[43mproject_name\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mproject_name\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    127\u001b[0m \u001b[43m    \u001b[49m\u001b[43mlogger\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mlogger\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    128\u001b[0m \u001b[43m    \u001b[49m\u001b[43moverwrite\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43moverwrite\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    129\u001b[0m \u001b[43m    \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    130\u001b[0m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    132\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mmax_model_size \u001b[38;5;241m=\u001b[39m max_model_size\n\u001b[0;32m    133\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39moptimizer \u001b[38;5;241m=\u001b[39m optimizer\n",
      "File \u001b[1;32mc:\\Users\\mathe\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\keras_tuner\\src\\engine\\base_tuner.py:127\u001b[0m, in \u001b[0;36mBaseTuner.__init__\u001b[1;34m(self, oracle, hypermodel, directory, project_name, overwrite, **kwargs)\u001b[0m\n\u001b[0;32m    124\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mtuner_id \u001b[38;5;241m=\u001b[39m os\u001b[38;5;241m.\u001b[39menviron\u001b[38;5;241m.\u001b[39mget(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mKERASTUNER_TUNER_ID\u001b[39m\u001b[38;5;124m\"\u001b[39m, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mtuner0\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[0;32m    126\u001b[0m \u001b[38;5;66;03m# Reloading state.\u001b[39;00m\n\u001b[1;32m--> 127\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m overwrite \u001b[38;5;129;01mand\u001b[39;00m backend\u001b[38;5;241m.\u001b[39mio\u001b[38;5;241m.\u001b[39mexists(\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_get_tuner_fname\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m):\n\u001b[0;32m    128\u001b[0m     \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mReloading Tuner from \u001b[39m\u001b[38;5;132;01m{\u001b[39;00m\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_get_tuner_fname()\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m\"\u001b[39m)\n\u001b[0;32m    129\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mreload()\n",
      "File \u001b[1;32mc:\\Users\\mathe\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\keras_tuner\\src\\engine\\base_tuner.py:475\u001b[0m, in \u001b[0;36mBaseTuner._get_tuner_fname\u001b[1;34m(self)\u001b[0m\n\u001b[0;32m    474\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21m_get_tuner_fname\u001b[39m(\u001b[38;5;28mself\u001b[39m):\n\u001b[1;32m--> 475\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m os\u001b[38;5;241m.\u001b[39mpath\u001b[38;5;241m.\u001b[39mjoin(\u001b[38;5;28mstr\u001b[39m(\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mproject_dir\u001b[49m), \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;132;01m{\u001b[39;00m\u001b[38;5;28mstr\u001b[39m(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mtuner_id)\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m.json\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n",
      "File \u001b[1;32mc:\\Users\\mathe\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\keras_tuner\\src\\engine\\base_tuner.py:466\u001b[0m, in \u001b[0;36mBaseTuner.project_dir\u001b[1;34m(self)\u001b[0m\n\u001b[0;32m    463\u001b[0m \u001b[38;5;129m@property\u001b[39m\n\u001b[0;32m    464\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mproject_dir\u001b[39m(\u001b[38;5;28mself\u001b[39m):\n\u001b[0;32m    465\u001b[0m     dirname \u001b[38;5;241m=\u001b[39m os\u001b[38;5;241m.\u001b[39mpath\u001b[38;5;241m.\u001b[39mjoin(\u001b[38;5;28mstr\u001b[39m(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mdirectory), \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mproject_name)\n\u001b[1;32m--> 466\u001b[0m     \u001b[43mutils\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mcreate_directory\u001b[49m\u001b[43m(\u001b[49m\u001b[43mdirname\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    467\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m dirname\n",
      "File \u001b[1;32mc:\\Users\\mathe\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\keras_tuner\\src\\utils.py:44\u001b[0m, in \u001b[0;36mcreate_directory\u001b[1;34m(path, remove_existing)\u001b[0m\n\u001b[0;32m     41\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mcreate_directory\u001b[39m(path, remove_existing\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mFalse\u001b[39;00m):\n\u001b[0;32m     42\u001b[0m     \u001b[38;5;66;03m# Create the directory if it doesn't exist.\u001b[39;00m\n\u001b[0;32m     43\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m backend\u001b[38;5;241m.\u001b[39mio\u001b[38;5;241m.\u001b[39mexists(path):\n\u001b[1;32m---> 44\u001b[0m         \u001b[43mbackend\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mio\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mmakedirs\u001b[49m\u001b[43m(\u001b[49m\u001b[43mpath\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m     46\u001b[0m     \u001b[38;5;66;03m# If it does exist, and remove_existing is specified,\u001b[39;00m\n\u001b[0;32m     47\u001b[0m     \u001b[38;5;66;03m# the directory will be removed and recreated.\u001b[39;00m\n\u001b[0;32m     48\u001b[0m     \u001b[38;5;28;01melif\u001b[39;00m remove_existing:\n",
      "File \u001b[1;32mc:\\Users\\mathe\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\keras_tuner\\src\\backend\\io.py:58\u001b[0m, in \u001b[0;36mmakedirs\u001b[1;34m(path)\u001b[0m\n\u001b[0;32m     56\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m tf \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[0;32m     57\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m os\u001b[38;5;241m.\u001b[39mmakedirs(path, exist_ok\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mTrue\u001b[39;00m)\n\u001b[1;32m---> 58\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mtf\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mio\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mgfile\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mmakedirs\u001b[49m\u001b[43m(\u001b[49m\u001b[43mpath\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[1;32mc:\\Users\\mathe\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\tensorflow\\python\\lib\\io\\file_io.py:513\u001b[0m, in \u001b[0;36mrecursive_create_dir_v2\u001b[1;34m(path)\u001b[0m\n\u001b[0;32m    501\u001b[0m \u001b[38;5;129m@tf_export\u001b[39m(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mio.gfile.makedirs\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[0;32m    502\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mrecursive_create_dir_v2\u001b[39m(path):\n\u001b[0;32m    503\u001b[0m \u001b[38;5;250m  \u001b[39m\u001b[38;5;124;03m\"\"\"Creates a directory and all parent/intermediate directories.\u001b[39;00m\n\u001b[0;32m    504\u001b[0m \n\u001b[0;32m    505\u001b[0m \u001b[38;5;124;03m  It succeeds if path already exists and is writable.\u001b[39;00m\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m    511\u001b[0m \u001b[38;5;124;03m    errors.OpError: If the operation fails.\u001b[39;00m\n\u001b[0;32m    512\u001b[0m \u001b[38;5;124;03m  \"\"\"\u001b[39;00m\n\u001b[1;32m--> 513\u001b[0m   \u001b[43m_pywrap_file_io\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mRecursivelyCreateDir\u001b[49m\u001b[43m(\u001b[49m\u001b[43mcompat\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mpath_to_bytes\u001b[49m\u001b[43m(\u001b[49m\u001b[43mpath\u001b[49m\u001b[43m)\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[1;31mFailedPreconditionError\u001b[0m: tuner_history is not a directory"
     ]
    }
   ],
   "source": [
    "tuner = kt.Hyperband(\n",
    "    model_builder, # Passando a função definida anteriormente com os detalhes da otimização de hiperparâmetros\n",
    "    objective = 'val_loss', # Definindo o objetivo da otimização de hiperparâmetros\n",
    "    max_epochs = 10, # Definindo o número máximo de epochs, ou seja, quantas vezes o modelo passará por todo o conjunto de treino durante o ajuste\n",
    "    factor = 3, # Fator de redução no número de epochs\n",
    "    directory = 'tuner_history', # Criando uma pasta para armazenar os resultados do treinamento, que podem ser reaproveitados posteriormente\n",
    "    project_name = 'mnist' # Definindo o nome do projeto e da pasta que vai armazenar os resultados do treinamento\n",
    ") # Criando uma variável para armazenar as informações da otimização de hiperparâmetros"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Treinando o modelo"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "early_stop = keras.callbacks.EarlyStopping( # Configurando um callback que interrompe o treinamento do modelo caso o desempenho pare de melhorar, com base em métricas monitoradas\n",
    "    patience = 5, # Definindo o patience, que é o número de epochs consecutivas em que a métrica monitorada pode não melhorar antes de interromper o treinamento\n",
    "    verbose = 1, # Definindo o verbose para exibir a informação de quando o callback for acionado caso aconteça\n",
    "    min_delta = 1E-4, # Definindo a menor diferença aceitável para considerar que houve melhora em uma métrica monitorada\n",
    ")\n",
    "\n",
    "tuner.search( # Treinando o modelo usando a otimização de hiperparâmetros\n",
    "    x_train, # Passando os valores de x de treino\n",
    "    y_train, # Passando os valores de y de treino\n",
    "    batch_size = 512, # Definindo o batch size, que é o número de amostras processadas de uma só vez antes de atualizar os pesos do modelo\n",
    "    validation_split = 0.2, # Definindo a proporção dos dados de treino que será separada para validação\n",
    "    callbacks = [early_stop] # Definindo o callback com a condição de parada definida anteriormente para interromper o treinamento do modelo\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "best_hps = tuner.get_best_hyperparameters()[0] # Armazenando os melhores hiperparâmetros em uma variável"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "best_hps.values # Visualizando os melhores hiperparâmetros"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = tuner.hypermodel.build(best_hps)\n",
    "\n",
    "history = model.fit(\n",
    "    x_train, \n",
    "    y_train,\n",
    "    epochs = 50, \n",
    "    batch_size = 512,\n",
    "    validation_split = 0.2,\n",
    "    callbacks = [early_stop]\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Fazendo o evaluate do modelo"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.evaluate(x_test, y_test) # Fazendo o evaluate do modelo"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Verificando possíveis condições de overfitting"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.plot(history.history['loss'], label='loss') # Plotando os valores de treino\n",
    "plt.plot(history.history['val_loss'], label='val_loss') # Plotando os valores de validação\n",
    "plt.legend() # Exibindo as legendas\n",
    "plt.show() # Exibindo o gráfico"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.plot(history.history['sparse_categorical_accuracy'], label='accuracy') # Plotando os valores de treino\n",
    "plt.plot(history.history['val_sparse_categorical_accuracy'], label='val_accuracy') # Plotando os valores de validação\n",
    "plt.legend() # Exibindo as legendas\n",
    "plt.show() # Exibindo o gráfico"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Nesse cenário, após a aplicação do pré processamento de Data Augmentation, os índicios de overfitting não aparecem mais, deixando assim o modelo pronto para ser utilizado com os dados reais."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Fazendo o predict do modelo com uma amostra dos dados"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig, axs = plt.subplots(figsize=(12,6), nrows=4, ncols=5) # Definindo o tamanho da figura para exibir os gráficos\n",
    "\n",
    "for i, ax in enumerate(axs.flat): # Criando uma estrutura de repetição para percorrer cada valor de x e plotar em um gráfico\n",
    "    ax.imshow(x_test[i], cmap='gray') # Plotando a imagem em um gráfico em escala de cinza\n",
    "    ax.set_title(f'Resposta correta: {y_test[i]}', size=10, pad=15) # Definindo o título do gráfico\n",
    "    ax.axis('off') # Desativando os títulos dos eixos\n",
    "    pred = model.predict(np.expand_dims(x_test[i], axis=0), verbose=0)[0] # Armazenando a previsão do modelo em uma variável\n",
    "    ax.text( # Adicionando um texto com a previsão do modelo\n",
    "        14, # Definindo a posição horizontal\n",
    "        -4, # Definindo a posição vertical\n",
    "        f'Previsão: {pred.argmax()} - {pred.max():.1%}', # Definindo o conteúdo do texto\n",
    "        color='green' if pred.argmax() == y_test[i] else 'red', # Definindo a cor do texto, variando de acordo com a previsão certa ou errada\n",
    "        verticalalignment = 'center', # Definindo o alinhamento vertical\n",
    "        horizontalalignment = 'center', # Definindo o alinhamento horizontal\n",
    "    )\n",
    "\n",
    "fig.subplots_adjust(hspace=0.6) # Ajustando o espaço entre cada subfigura\n",
    "\n",
    "plt.show() # Exibindo os gráficos"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Testando o modelo em imagens criadas manualmente"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "real_images_dir = Path('../images/real_images') # Armazenando em uma variável o caminho da pasta das imagens criadas manualmente\n",
    "\n",
    "all_pred = {} # Criando um dicionário vazio para armazenar as previsões do modelo e poder verificar as probabilidades de cada resultado posteriormente\n",
    "\n",
    "fig, axs = plt.subplots(figsize=(12,4), nrows=2, ncols=5) # Definindo o tamanho da figura para exibir os gráficos\n",
    "\n",
    "for i, (img, ax) in enumerate(zip(sorted(real_images_dir.glob('*.png')), axs.flat)): # Criando uma estrutura de repetição para percorrer as imagens criadas e plotar em um gráfico\n",
    "\n",
    "    name = img.name.split('.')[0] # Armazenando em uma variável o nome da imagem com o número correto a partir do . como separador\n",
    "\n",
    "    img = keras.preprocessing.image.load_img(\n",
    "        img, target_size=(28, 28), color_mode='grayscale'\n",
    "    ) # Ajustando a escala da imagem, pois o modelo foi treinado com imagens com 28 x 28 pixels, e as que fizemos possuem 128 x 128\n",
    "    img_array = keras.preprocessing.image.img_to_array(img) # Convertendo a imagem para um array NumPy\n",
    "    img_array = 255 - img_array # Invertendo as cores da imagem, pois o modelo foi treinado com imagens com fundo preto, e as que fizemos são com fundo branco\n",
    "    img_array = tf.expand_dims(img_array, 0) # Adicionando uma dimensão extra\n",
    "\n",
    "    pred = model.predict(img_array, verbose=0) # Armazenando o valor previsto em uma variável\n",
    "    all_pred[name] = pred # Adicionando a previsão no dicionário criado anteriormente para isso\n",
    "\n",
    "    ax.imshow(img_array[0], cmap='gray') # Plotando a imagem em um gráfico em escala de cinza\n",
    "    ax.set_title(f'Resposta correta: {name}', size=10, pad=25) # Definindo o título do gráfico\n",
    "    ax.axis('off') # Desativando os títulos dos eixos\n",
    "    ax.text( # Adicionando um texto com a previsão do modelo\n",
    "        14, # Definindo a posição horizontal\n",
    "        -4, # Definindo a posição vertical\n",
    "        f'Previsão: {pred.argmax()} - {pred.max():.1%}', # Definindo o conteúdo do texto\n",
    "        color='green' if str(pred.argmax()) == name else 'red', # Definindo a cor do texto, variando de acordo com a previsão certa ou errada\n",
    "        verticalalignment = 'center', # Definindo o alinhamento vertical\n",
    "        horizontalalignment = 'center', # Definindo o alinhamento horizontal\n",
    "    )\n",
    "\n",
    "fig.subplots_adjust(hspace=0.6) # Ajustando o espaço entre cada subfigura\n",
    "\n",
    "plt.show() # Exibindo os gráficos\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Verificando as probabilidades de resultados para cada imagem"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "formatted_pred = { # Criando um dicionário para formatar os valores \n",
    "    key: np.array([['{:.1f}%'.format(x * 100) for x in row] for row in value]) \n",
    "    for key, value in all_pred.items()\n",
    "}\n",
    "\n",
    "for key, value in formatted_pred.items(): # Criando uma estrutura de repetição para printar os resultados de chave e valor das previsões\n",
    "    print(f'{key}: {value}')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
